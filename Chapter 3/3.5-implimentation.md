# ðŸŒ 3.5 â€” Implementation

## Overview

This section moves from **theory (what routers/switches do)** to **practice (how theyâ€™re built)**.  
It explores how network devices evolved from **general-purpose computers** to **specialized, programmable hardware**, and now to **software-defined, cloud-scale systems**.

### Covered Topics
1. **Software Switches** â€“ CPU-driven packet forwarding.  
2. **Hardware Switches** â€“ ASIC/NPU-accelerated high-speed switching.  
3. **Software Defined Networking (SDN)** â€“ disaggregating control and data planes.

---

## 3.5.1 Software Switch

### ðŸ”¹ Concept

A **software switch** uses a **general-purpose CPU** and multiple **Network Interface Cards (NICs)** to perform packet forwarding entirely in software.

**Process Flow:**
1. **NIC 1** receives a packet â†’ **DMA** moves it to **main memory**.  
2. **CPU** inspects headers â†’ determines output port.  
3. **NIC 2** transmits the packet â†’ outgoing link.

This is **store-and-forward switching** â€” packets are buffered in memory between arrival and departure.

---

### ðŸ”¹ Performance Bottlenecks

1. **Memory Bandwidth Limits**  
   - All packets traverse **main memory**.  
   - Example: 1333 MHz Ã— 64-bit bus â‰ˆ 100 Gbps â€” fine for a few 10G ports but not large-scale.

2. **Per-Packet Overhead**  
   - Small packets increase CPU workload.  
   - Example: 40 Mpps Ã— 64 B Ã— 8 = ~20 Gbps â†’ only ~1 Gbps/port on a 16-port switch.

3. **Scaling Limits**  
   - CPU and memory bottlenecks cap software forwarding throughput.

---

### ðŸ”¹ Control vs Data Plane

| Plane | Function |
|-------|-----------|
| **Control Plane** | Runs routing protocols (OSPF, RIP, BGP). |
| **Data Plane** | Performs packet forwarding and table lookups. |

In software switches, both planes share the CPU. Performance improves by:
- Optimizing or offloading the data plane.  
- Defining a clear **controlâ€“data interface** (foundation of SDN).

ðŸ§  **Analogy:** Control plane = *brains* ðŸ§©; Data plane = *muscle* âš¡

---

## 3.5.2 Hardware Switch

### ðŸ”¹ Motivation

Software forwarding canâ€™t reach high throughput.  
**Hardware switches** use **ASICs** for **line-rate packet processing** (full wire speed).

**Challenge:** ASICs are fast but rigid â€” years to redesign.  
**Goal:** Combine **ASIC speed** with **software flexibility**.

---

### ðŸ”¹ Modern Solution â€” Bare-Metal Switches

Emergence of **Network Processing Units (NPUs)** â†’ **bare-metal switch designs**:

- Commodity, open hardware (e.g., via **Open Compute Project, OCP**).  
- Programmable software stacks (open-source L2/L3).  
- Separation of **hardware** and **network OS**.

**Users can:**
- Purchase base hardware.  
- Install open or custom network OS.  
- Program L2/L3 behavior or hybrids.

---

### ðŸ”¹ Architecture Overview

A **bare-metal switch** includes three key components:

| Component | Role |
|------------|------|
| **Control CPU** | Runs control-plane software (routing, config). |
| **Network Processing Unit (NPU)** | Accelerates data-plane tasks (header parsing, forwarding). |
| **Commodity Modules** | Optical/electrical transceivers (e.g., SFP+). |

- NPUs achieve multi-terabit throughput (e.g., 32Ã—100G ports).  
- Architecture mirrors modern computing: modular, open, scalable.

---

### ðŸ”¹ Inside the NPU

| Component | Function |
|------------|-----------|
| **SRAM** | Ultra-fast buffer (~10Ã— faster than DRAM). |
| **TCAM** | Supports wildcard header matches using ternary logic. |
| **Forwarding Pipeline** | Multi-stage ASIC path for matching + actions. |

- Each pipeline stage handles one header layer (MAC â†’ IP â†’ ACL).  
- Multiple packets process concurrently â†’ **nanosecond latency**, **Tbps throughput**.

---

### ðŸ”¹ Programming the NPU

- **Fixed Pipeline:** Supports standard protocols (Ethernet, IP).  
- **Programmable Pipeline:** Defined via **P4 language**.

**P4** = Open standard defining *Matchâ€“Action tables*:  
> â€œIf header = X â†’ then forward to Y.â€

Allows flexible forwarding logic without hardware redesign.

---

### ðŸ”¹ The Big Picture

Networking now mirrors computing:
- **Open hardware** (OCP).  
- **Programmable software stacks** (P4, open NOS).  
- **Commodity economics** â€” anyone can assemble a high-performance switch.

---

## 3.5.3 Software Defined Networking (SDN)

### ðŸ”¹ Concept

**SDN = Disaggregated Networking**

- Separates **control plane** (decision logic) from **data plane** (packet forwarding).  
- Standardized by **OpenFlow**, defining the controlâ€“data interface.

ðŸŽ¯ **Goal:** Any controller can program any hardware switch â†’ breaking vendor lock-in.

---

### ðŸ”¹ Logical Centralization

Traditional: Each switch runs its own routing logic.  
SDN: A **logically centralized controller** manages the whole network.

- Maintains a **global network map** (switches, links, ports).  
- Computes optimal routes.  
- Pushes **forwarding rules** into switches.

> â€œLogically centralizedâ€ â‰  single machine â€” distributed controllers can provide scale & redundancy.

---

### ðŸ”¹ SDN in the Cloud

Cloud hyperscalers (Google, Microsoft, AWS) use SDN to:
- Manage data center fabrics and inter-DC backbones.  
- Dynamically reroute traffic.  
- Optimize for latency, utilization, and redundancy.

ðŸ“ˆ Since 2012, **virtual (software) switches** have outnumbered physical switches in large data centers.

---

### ðŸ”¹ Network Operating System (NOS)

Acts like **Linux for networks**.

**Responsibilities:**
- Maintains global **Network Map**.  
- Detects link/switch changes.  
- Exposes APIs for **Control Applications** (Apps).

Apps define policies (e.g., routing, load balancing, ACLs),  
while the NOS handles distributed coordination.

> Example: A control app can run Dijkstraâ€™s algorithm on the network map directly â€” no link-state flooding required.

---

### ðŸ”¹ Key Takeaways on SDN

- SDN doesnâ€™t replace routing â€” it **relocates** control logic.  
- Enables **centralized optimization** and **hardwareâ€“software decoupling**.  
- Still evolving â€” trade-offs between **centralized** and **distributed** models.

**Adoption:**  
- Rapid in hyperscale data centers.  
- Gradual in enterprises & telcos due to tooling and expertise gaps.

---

## ðŸŒŸ Key Takeaways (Section 3.5)

| Concept | Summary |
|----------|----------|
| **Software Switch** | CPU + NICs forward packets in software; limited by memory and processing. |
| **Control vs Data Plane** | Control = logic, Data = forwarding; foundation for SDN. |
| **Hardware Switch** | ASIC/NPU-accelerated data plane; high-speed, programmable. |
| **Bare-Metal Switch** | Open, modular hardware + software (OCP model). |
| **P4 Language** | Defines programmable matchâ€“action pipelines for NPUs. |
| **SDN (Software Defined Networking)** | Separates control/data planes; centralized control via OpenFlow. |
| **Network OS (NOS)** | Provides APIs + global state for control apps. |
| **OpenFlow Interface** | Original SDN protocol linking controllers and switches. |
| **Industry Shift** | Networking is now open, programmable, and software-driven. |

---

## ðŸ“˜ Glossary

| Term | Definition |
|------|-------------|
| **Software Switch** | Packet forwarding using CPU + NICs entirely in software. |
| **NIC (Network Interface Card)** | Hardware interface connecting to a network. |
| **DMA (Direct Memory Access)** | Moves packets between NIC and memory without CPU. |
| **Control Plane** | Manages routing and configuration. |
| **Data Plane** | Performs per-packet forwarding. |
| **ASIC (Application-Specific Integrated Circuit)** | Custom hardware optimized for packet processing. |
| **NPU (Network Processing Unit)** | Specialized processor for packet parsing and forwarding. |
| **SRAM / DRAM** | Memory types â€” SRAM is faster, used for buffers. |
| **TCAM (Ternary Content Addressable Memory)** | High-speed memory supporting wildcard matching. |
| **Forwarding Pipeline** | Multi-stage matching/action process in hardware. |
| **P4 Language** | Open language for defining programmable packet pipelines. |
| **Bare-Metal Switch** | Commodity switch hardware with open software stack. |
| **SDN (Software Defined Networking)** | Separates control from data for flexibility. |
| **OpenFlow** | Protocol linking SDN controllers and switches. |
| **NOS (Network Operating System)** | Manages global network state and provides APIs. |
| **Network Map** | Logical view of network topology. |
| **Control App** | Application implementing policies via the NOS. |
| **Disaggregation** | Separation of hardware and software layers. |
| **Logical Centralization** | Global, unified view of the network across distributed controllers. |

---
